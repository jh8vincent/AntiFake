{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Job Skills Analysis in Data Analyst\n",
        "### Project Member: \n",
        "#### xxxxxx\n",
        "#### xxxxxx\n",
        "#### xxxxxx\n",
        "\n",
        "\n",
        "Date: XX/XX/XXXX\n",
        "\n",
        "Version: 1.0\n",
        "\n",
        "ProgrammingEnvironment: Python 3.8 and Jupyter notebook\n",
        "\n",
        "Tools used: \n",
        "* tableau (for data visualisation)\n",
        "* DB Browser (for database management) \n",
        "* Pycharm (for data extraction, data wrangling) \n",
        "\n"
      ],
      "metadata": {
        "id": "RIPcoIjVBm6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "* [1. Introduction](#sec_1)\n",
        "* [1.1. Project Objective](#sec_1.1)\n",
        "* [1.2 Target Audience](#sec_1.2)\n",
        "* [1.3 Project Assumption](#sec_1.3)\n",
        "* [1.4 Key Insights](#sec_1.4)\n",
        "\n",
        "* [2. Data Wrangling and Methodology](#sec_2)\n",
        "* [2.1 Data Cleaning - How to Use Regular Expression to Clean the Job Salary and Job Ad Posted Time?](#sec_2.1)\n",
        "* [2.1.1 Job Salary Data Cleaning](#sec_2.1.1)\n",
        "* [2.1.2 Job Ad Posted Time Data Cleaning](#sec_2.1.2)\n",
        "* [2.2 Dimensional Modeling Method – How to Model and Transform the Data into Job Details Fact table and Job Info Dimension Table?](#sec_2.2)\n",
        "* [2.2.1 Identifying Business Objective](#sec_2.2.1)\n",
        "* [2.2.2 Identifying Granularity](#sec_2.2.2)\n",
        "* [2.2.3 Identifying Dimensions](#sec_2.2.3)\n",
        "* [2.2.4 Identifying Facts](#sec_2.2.4)\n",
        "* [2.2.5 Building the schema](#sec_2.2.5)\n",
        "* [2.3 Data Extracting - How to Filter the Related Recruitment Data for Data Analyst, Data Engineer, Data Scientist from More Than 10,000 Job Descriptions?](#sec_2.3)\n",
        "* [2.4 Term Frequency Analysis – How to Use Word Count to Filter the Key Skills?](#sec_2.4)\n",
        "* [2.5 Documentary Frequency Analysis – How to Identify the Importance of Key Skills?](#sec_2.5)\n",
        "* [2.6 Requirements & Getting Started](#sec_2.6)\n",
        "* [3. Exploratory Data Analysis](#sec_3)\n",
        "* [4. Conclusion](#sec_4)\n",
        "* [5. References](#sec_5)"
      ],
      "metadata": {
        "id": "dpKuJ7O9Bm6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction <a class=\"anchor\" id=\"sec_1\"></a>\n",
        "### 1.1 Project Objective <a class=\"anchor\" id=\"sec_1.1\"></a>\n",
        "\n",
        "This project extract, clean, explore and analyze job description data of three popular job titles -- Data Analyst, Data Engineer and Data Scientist, in recent couple of months from SEEK website. This GitHub repo contains all the codes and datasets for this project. The objectives of this project are:\n",
        "\n",
        "* Clean dirty salary and datetime data, then transform them for analytics.\n",
        "* Exploratory data analysis, e.g.\n",
        "  - find the hottest technical and soft skills for different job titles -- Data Analyst, Data Engineer and Data\n",
        "Scientist.\n",
        "  - analyze the salary differences for different job titles and job types.\n",
        "  - analyze the available positions and required technical skills in different regions.\n",
        "  - analyze the possible relationship between salary range and required technical skills.\n",
        "* Provide career path references for people who would like to be a Data Analyst, Data Engineer or Data Scientist.\n",
        "\n",
        "\n",
        "### 1.2 Target Audience <a class=\"anchor\" id=\"sec_1.2\"></a>\n",
        "\n",
        "* People who would like to be a Data Analyst, Data Engineer, or Data Scientist.\n",
        "\n",
        "### 1.3 Project Assumption  <a class=\"anchor\" id=\"sec_1.3\"></a>\n",
        "\n",
        "* Assuming that the SEEK website can represent the current situation and trends of job market in Australia.\n",
        "\n",
        "* Assuming the recruitment data on the SEEK website is accurate.\n",
        "\n",
        "* Assume that people always would like to put the most important information first, for example, the higher the\n",
        "position in the job advertisement. In other words, the earlier the relevant skills appear means that they are more\n",
        "important to the company.\n",
        "\n",
        "### 1.4 Key Insights  <a class=\"anchor\" id=\"sec_1.4\"></a>\n",
        "\n",
        "This project extract job description data of three popular job titles -- Data Analyst, Data Engineer and Data Scientist,\n",
        "in recent couple of months from SEEK website. The job locations include eight major cities in Australia – Sydney,\n",
        "Melbourne, Perth, Brisbane, Gold Coast, Adelaide, ACT and Hobart. Among them, there are 2224 job advertisements\n",
        "for Data Analyst, 1180 job advertisements for Data Engineer, and 529 job advertisements for Data Scientist. From the\n",
        "analyzed results, the main conclusions can be summarized as follows:\n",
        "\n",
        "* Top hottest required skills for Data Analyst: SQL, Excel, Power BI, Tableau, Python, Cloud, Reporting and\n",
        "Communication Skills\n",
        "\n",
        "* Top hottest required skills for Data Engineer: Cloud, SQL, AWS, Python, Azure, ETL/ELT, Communication,\n",
        "Infrastructure;\n",
        "\n",
        "* Top hottest required skills for Data Scientist: Artificial Intelligence, Python, Communication, Machine\n",
        "Learning, Data Science, Research, SQL, Statistics.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UR4_ZeqsBm6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OlGFnSx3CvNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Wrangling and Methodology <a class=\"anchor\" id=\"sec_2\"></a>\n",
        "\n",
        "### 2.1 Data Cleaning - How to Use Regular Expression to Clean the Job Salary and Job Ad Posted Time? <a class=\"anchor\" id=\"sec_2.1\"></a>\n",
        "\n",
        "In this project, we did not analyze the job salary because the data was not plenty enough for the moment. This\n",
        "project focuses more on the analysis of required skills.\n",
        "Moreover, if we have enough recruitment data for several years, we can also analyze the trend of the data job\n",
        "market, for example, how the hottest required skills change over time.\n",
        "\n",
        "\n",
        "#### 2.1.1 Job Salary Data Cleaning <a class=\"anchor\" id=\"sec_2.1.1\"></a>\n",
        "\n",
        "Firstly, we use Regular Expression to extract the salary data and transform them into float numbers from the\n",
        "database.\n",
        "Then, based on different salary range, the job salary can be divided into following three categories:\n",
        "* If salary is lower than 200, it is paid by per hour;\n",
        "* If salary is greater than 200 and lower than 2000, it is paid by per day;\n",
        "* If salary is greater than 2000, it is paid by per annual.\n",
        "\n",
        "In such way, the annual salary can be calculated according to the full-time working hours from Australian\n",
        "government website. There are 251 working days or 2008 working hours per year for a full-time working position.\n",
        "Finally, the data can be converted into a CSV file and needs to be manually checked for errors.\n",
        "\n",
        "#### 2.1.2 Job Ad Posted Time Data Cleaning <a class=\"anchor\" id=\"sec_2.1.2\"></a>\n",
        "\n",
        "The job Ad posted time usually have the following suffixes:\n",
        "* ‘m’ means the job ad was posted minutes ago;\n",
        "* ‘h’ means the job ad was posted hours before;\n",
        "* ‘d’ means the job ad was posted days ago.\n",
        "\n",
        "Based on these suffixes, we can use the Python datetime library to calculate the Universal Time Coordinated\n",
        "date of the job ad posted time.\n",
        "\n",
        "### 2.2 Dimensional Modeling Method – How to Model and Transform the Data into Job Details Fact table and Job Info Dimension Table? <a class=\"anchor\" id=\"sec_2.2\"></a>\n",
        "\n",
        "In this section, the dimensional data modelling technique will be applied to construct the data warehouse which\n",
        "could store and retrieve data quickly for the further analysis (Saxena & Agarwal, 2014). By applying the DDM in this project, the data\n",
        "behavior and domain can be easily understood, and their performance can be optimized.\n",
        "\n",
        "\n",
        "#### 2.2.1 Identifying Business Objective <a class=\"anchor\" id=\"sec_2.2.1\"></a>\n",
        "\n",
        "Based on the data we have collected, the business objective is to identify the required skills in various job\n",
        "position for the people who would like establish their career in the field of data. Therefore, the key words\n",
        "regarding skills will be extracted and analyzed from the job details.\n",
        "\n",
        "#### 2.2.2 Identifying Granularity <a class=\"anchor\" id=\"sec_2.2.2\"></a>\n",
        "\n",
        "Granularity is the lowest level of information for the tables in the data warehouse. The grain will be used for\n",
        "identifying the level of details for the business problem. Hence, the grain of fact table are job_id, section_id, and\n",
        "line_id which can be used to identify each job details. The grain of dimensional table is job_id which could be\n",
        "used to identify job information.\n",
        "\n",
        "#### 2.2.3 Identifying Dimensions <a class=\"anchor\" id=\"sec_2.2.3\"></a>\n",
        "\n",
        "Dimensions are used for categorizing and describing facts and measures. The job information of each job can be\n",
        "classified as the dimensions in this project. The dimensional table is used for storing the descriptive data and\n",
        "providing the context to the fact creation. In this case, the Job Info Dimensional Table contains all the\n",
        "dimensions of each job such as the job title, job company, job area, etc.\n",
        "\n",
        "#### 2.2.4 Identifying Facts <a class=\"anchor\" id=\"sec_2.2.4\"></a>\n",
        "\n",
        "Since the aim of this project is to investigate the job skills that are required for each position. The fact refers to\n",
        "each job details that is posted as well as the fact table is utilized for storing a collection of measures such as\n",
        "section id, line id, job details, etc.\n",
        "\n",
        "#### 2.2.5 Building the schema <a class=\"anchor\" id=\"sec_2.2.5\"></a>\n",
        "\n",
        "The star schema will be developed based on the following DDM analysis and the Entity Relational Diagram.\n",
        "\n",
        "### 2.3 Data Extracting - How to Filter the Related Recruitment Data for Data Analyst, Data Engineer, Data Scientist from More Than 10,000 Job Descriptions? <a class=\"anchor\" id=\"sec_2.3\"></a>\n",
        "\n",
        "The search algorithm from SEEK website brings up lots of irrelevant job titles, such as business intelligence,\n",
        "accountant, etc. Therefore, before further analysis, we need to filter out the related recruitment data for Data\n",
        "Analyst, Data Engineer, Data Scientist. In this project, we can use SQL LIKE and UNLIKE operator to identify\n",
        "whether if the job title belongs to these three titles or not.\n",
        "Finally, from 13,000 job advertisements, there are 2224job advertisements for Data Analyst, 1180 job\n",
        "advertisements for Data Engineer, and 529 job advertisements for Data Scientist. From the analyzed results, the\n",
        "main conclusions can be summarized as follows:\n",
        "\n",
        "\n",
        "\n",
        "### 2.4 Term Frequency Analysis – How to Use Word Count to Filter the Key Skills? <a class=\"anchor\" id=\"sec_2.4\"></a>\n",
        "\n",
        "From the downloaded job details data, we can calculate the appeared frequency of each meaningful word(s),\n",
        "including technical and soft skills. Then through the word cloud we can see which technologies are more\n",
        "important than others. We can also use SQL LIKE operator to identify which statements contain these keywords\n",
        "and count the distinct job ad number. According to the above word count and term frequency analysis, we can\n",
        "filter out 46 highly-demand technical and 12 soft skills in the job market.\n",
        "\n",
        "__The 46 highly-demand skills are as follows:__\n",
        "\n",
        "SQL, Excel, Power BI, Tableau, Python, Cloud, Azure, AWS, GCP, API, Pipeline, Dimension Modelling,\n",
        "ETL/ELT, DevOps, CI/CD, Spark, Java, , Scala, Oracle, Kubernetes, Docker, Apache, Kafka, Linux, Snowflake,\n",
        "Data Warehouse, Data Modelling, Data Visualization, Data Migration, Data Management, Data Integration, Data\n",
        "Platform, Data Architecture, Data Factory, Databricks, Data Science, Machine Learning, Computer Science,\n",
        "Research, Statistic, Mathematics, Quantitative, Algorithm, Deep Learning, Statistical Analysis;\n",
        "\n",
        "__The 12 highly-demand soft skills are as follows:__\n",
        "\n",
        "Communication Skill, Reporting, Stakeholder, Agile, Project Management, Business Intelligence, Decision\n",
        "Making, Interpersonal, Time Management, Troubleshoot, Tertiary Qualification, PhD\n",
        "\n",
        "\n",
        "### 2.5 Documentary Frequency Analysis – How to Identify the Importance of Key Skills? <a class=\"anchor\" id=\"sec_2.5\"></a>\n",
        "\n",
        "\n",
        "In this section, to further illustrate which skills are more important, we select 6-10 skills most in demand for the\n",
        "following documentary frequency analysis.\n",
        "As elaborated in the assumption chapter, people always would like to put the most important information first, for\n",
        "example, the higher the position in the job advertisement. We can analyze the average appeared line number of\n",
        "these important skills. We can also categorize their first occurrence line numbers into three range: 1~3, 4~5 and\n",
        "6+. From these specific analyses, we can distinguish the order of importance of these skills. The top hottest\n",
        "required skills for Data Analyst, Data Engineer and Data Scientist are as follows:\n",
        "\n",
        "Data Analyst:__ SQL, Excel, Power BI, Tableau, Python, Cloud, Reporting and Communication Skills;__\n",
        "\n",
        "Data Engineer: __Cloud, SQL, AWS, Python, Azure, ETL/ELT, Communication, Infrastructure;__\n",
        "\n",
        "Data Scientist: __Artificial Intelligence, Python, Communication, Machine Learning, Data Science, Research,\n",
        "SQL, Statistics.__\n",
        "\n",
        "Tools used in the project\n",
        "\n",
        "Programming Environment: __Python 3.8 and Jupyter Notebook__\n",
        "Data Extraction, Data Cleaning and Data Wrangling: __PyCharm__\n",
        "Data Wrangling and Database Management: __DB Browser for SQLite3 and Elephant DB for PostgreSQL__\n",
        "Data Visualization: __Power BI and Tableau__\n",
        "\n",
        "\n",
        "\n",
        "### 2.6 Requirements & Getting Started <a class=\"anchor\" id=\"sec_2.6\"></a>\n",
        "\n",
        "\n",
        "__Dependencies include:__\n",
        "\n",
        "import json\n",
        "from glob import glob\n",
        "import sqlite3\n",
        "import re\n",
        "import pandas\n",
        "from typing import Optional, Tuple, List, Iterable, Any\n",
        "from nltk.corpus import stopwords\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import requests\n",
        "import urllib.parse\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Tag\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aAOVjnRjBm6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploratory Data Analysis<a class=\"anchor\" id=\"sec_3\"></a>\n",
        "\n",
        "In this part, average line number of key skills in each job title will be explored to discover skill importance, where the top skills mean more significant. Moreover, job count will be conducted for each key skill in three job titles, which aims to examine hottest skills in each job titles.\n",
        "\n",
        "### 3.1\tRequired Skills for Data Analyst <a class=\"anchor\" id=\"sec_3.1\"></a>\n",
        "\n",
        "#### 3.1.1\tTerm Frequency and Word Cloud for Data Analyst\n",
        "\n",
        "From the downloaded job details, we can calculate the appeared frequency of each meaningful word(s), including technical and soft skills. Then we can draw Word Cloud as shown Figure 3.1.\n",
        "\n",
        "**Figure 3.1**. Word Cloud for Data Analyst.\n",
        "\n",
        "<img src=\"02.png\">\n",
        "\n",
        "#### 3.1.2\tDocumentary Frequency Analysis and Technical Skills Required to be a Data Analyst\n",
        "\n",
        "From skills in data analyst, skills like sql, management, excel, reporting and communication are the hottest. To discover more, five soft skills and five technical skills are chosen, namely sql, excel, power bi, tableau, python, and management, reporting, communication, design, insights.\n",
        "\n",
        "**Figure 3.2**. Skills Required to be a Data Analyst.\n",
        "\n",
        "<img src=\"03.png\">\n",
        "\n",
        "#### 3.1.3\tRanked Line in the Job Description of Technical Skills \n",
        "\n",
        "From these specific analyses, we can distinguish the order of importance of these skills. \n",
        "\n",
        "**Data Analyst: SQL, Excel, Power BI, Tableau, Python, Data Visualization, Reporting and Communication Skills.**\n",
        "\n",
        "**Figure 3.3**.  Ranked Line in the Job Description of Skills for Data Analyst.\n",
        "\n",
        "<img src=\"06.png\">\n",
        "\n",
        "#### 3.1.4\tAverage Ranked Line in the Job Description of Technical Skills \n",
        "We can also calculate the average ranked line in the job description of these skills, as shown in Figure 3.6. \n",
        "From the figure shown, statistics and quantitative rank at the top which means they are important in data analyst jobs, and besides, technical skills such as ssas, r, sql, power bi and python are in line between 3 and 4.2. While skills like aws and azure are less important than the former skills.\n",
        "\n",
        "**Figure 3.4**.  Average Ranked Line in the Job Description of Skills\n",
        "\n",
        "<img src=\"09.png\">\n",
        "\n"
      ],
      "metadata": {
        "id": "TCXAWcJXBm6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2\tRequired Skills for Data Engineer <a class=\"anchor\" id=\"sec_3.2\"></a>\n",
        "\n",
        "#### 3.2.1\tTerm Frequency and Word Cloud for Data Engineer\n",
        "\n",
        "According to the job details, we can get the term frequency of each meaningful word or grams, including technical and soft skills. Then we have Word Cloud as shown from Figure 3.5.\n",
        "\n",
        "**Figure 3.5**. Word Cloud for Data Engineer.\n",
        "\n",
        "<img src=\"10.png\">\n",
        "\n",
        "#### 3.2.2\tDocumentary Frequency Analysis and Technical Skills Required to be a Data Engineer\n",
        "\n",
        "After count job numbers for each skill in data engineer, we can observe skills like cloud, sql, aws, azure, python and communication are the hottest. To discover more, twelve soft skills and six technical skills are chosen.\n",
        "\n",
        "**Figure 3.6**. Skills Required to be a Data Engineer.\n",
        "\n",
        "<img src=\"images/11.png\">\n",
        "<img src=\"images/12.png\">\n",
        "\n",
        "#### 3.2.3\tRanked Line in the Job Description of Technical Skills \n",
        "\n",
        "The order of job descriptions means skill importance, which assumes that we put important information at the beginning lines and which menas those skills are significant.\n",
        "\n",
        "\n",
        "**Figure 3.7**.  Ranked Line in the Job Description of Skills for Data Engineer.\n",
        "\n",
        "<img src=\"13.png\">\n",
        "\n",
        "\n",
        "#### 3.2.4\tAverage Ranked Line in the Job Description of Technical Skills \n",
        "We can also calculate the average ranked line in the job description of these skills, as shown in Figure 3.8. \n",
        "From the picture shown, data warehouse, data architecture and gcp rank at the top which means they are significant in data engineer jobs, and besides, skills related to cloud  such as aws, cloud, api, are also ranked at the top, while those soft skills like communication and documentation are less significant which are placed at around line 6. \n",
        "\n",
        "**Figure 3.8**.  Average Ranked Line in the Job Description of Skills\n",
        "\n",
        "<img src=\"16.png\">\n",
        "\n"
      ],
      "metadata": {
        "id": "V4GmdJAyRBUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3\tRequired Skills for Data Scientist <a class=\"anchor\" id=\"sec_3.3\"></a>\n",
        "\n",
        "#### 3.3.1\tTerm Frequency and Word Cloud for Data Scientist\n",
        "\n",
        "From the job descriptions, we can calculate the term frequency of each meaningful word or words, including technical and soft skills. Then we can draw Word Cloud as shown Figure 3.9.\n",
        "\n",
        "**Figure 3.9**. Word Cloud for Data Scientist.\n",
        "\n",
        "<img src=\"0222.png\">\n",
        "\n",
        "#### 3.3.2\tDocumentary Frequency Analysis and Technical Skills Required to be a Data Scientist\n",
        "\n",
        "From skills in data scientist, ai appear near twice compared to the second skill python, skills like machine learning and sql are also appear mostly, while some skills like aws, spark, power bi and azure appear less. To explore more, ai, python, machine learning, sql, statistics, cloud are as technical skills, while soft skills such as communication, stakeholder, agile, reporting, project managemennt, interpersonal skill, decision making troubleshooting and business inntelligence are explored.\n",
        "\n",
        "\n",
        "**Figure 3.10**. Skills Required to be a Data Scientist.\n",
        "\n",
        "<img src=\"17.png\">\n",
        "<img src=\"18.png\">\n",
        "\n",
        "#### 3.3.3\tRanked Line in the Job Description of Technical Skills \n",
        "\n",
        "From these specific analyses, we can distinguish the order of importance of these skills.\n",
        "\n",
        "We can see that there are 244 jobs have placed ai at the top lines and 171 jobs place machine learning at the front and near 150 jobs place python and data science at the beginning, which shows that those skills are important in data scientist. We also could see soft skill communication are appeared more in the end lines, less appeared in line between 4 and 5, and least appeared in the first three lines, which means most jobs regard this skill less important than other skills like ai, python, machine learning. \n",
        "\n",
        "\n",
        "**Figure 3.11**.  Ranked Line in the Job Description of Skills for Data Scientist.\n",
        "\n",
        "<img src=\"19.png\">\n",
        "\n",
        "\n",
        "#### 3.3.4\tAverage Ranked Line in the Job Description of Technical Skills \n",
        "We can also calculate the average ranked line in the job description of these skills, as shown in Figure 3.12. \n",
        "According to pictures above, quantitative, natural language processing, mathematics, machine learning are averagely place at the first three lines, while those programming languages like python, sql, r rank at between line 3 and line 4 which means those skills are less important than mathematical skills but they still are important. Similar to data engineer, those soft skills like management and communication are ranked at the end.\n",
        "\n",
        "**Figure 3.12**.  Average Ranked Line in the Job Description of Skills\n",
        "\n",
        "<img src=\"20.png\">\n",
        "\n"
      ],
      "metadata": {
        "id": "A22uHvisRers"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4\tCarrier Path<a class=\"anchor\" id=\"sec_3.4\"></a>\n",
        "\n",
        "#### 3.4.1\tThe Necessary Skills to Become a Data Analyst, Data Engineer and Data Scientist\n",
        "\n",
        "From the analysis elaborated above, we can conclude that the hottest required skills for Data Analyst are **SQL, Excel, Power BI, Visualization, Tableau, Python, Reporting and Communication Skills**; the hottest required skills for Data Engineer are **Cloud, SQL, AWS, Python, Azure, ETL/ELT, Communication, Infrastructure**; the top hottest required skills for Data Scientist are **Artificial Intelligence, Python, Communication, Machine Learning, Data Science, Research, SQL, Statistics**.\n",
        "Then we can draw the dashboard for these necessary skills to be a Data Analyst, Data Engineer, and Data Scientist, as shown in Figure 3.19 – 3.21. \n",
        "\n",
        "**Figure 3.19**.  Dashboard for the Necessary Skills to be a Data Analyst\n",
        "<img src=\"26.png\">\n",
        "\n",
        "**Figure 3.20**.  Dashboard for the Necessary Skills to be a Data Engineer\n",
        "<img src=\"27.png\">\n",
        "\n",
        "**Figure 3.21**.  Dashboard for Necessary Skills to be a Data Scientist\n",
        "<img src=\"28.png\">\n",
        "\n",
        "#### 3.4.2\tAdditional Skills while Switching Between Data Analyst, Data Engineer and Data Scientist\n",
        "\n",
        "From the following schematic diagram of the career path between Data Analyst, Data Engineer and Data Scientist, we can tell that SQL, Python and communication skills are mandatory skills in the big data field.\n",
        "\n",
        "If people want to change carrier from Data Analyst to Data Engineer, they must **obtain Cloud experience**, such as AWS, Azure. They will also need to obtain other necessary skills and experience such as ETL/ELT, Spark, Data Pipeline, DevOps.\n",
        "\n",
        "If people who are Data Analysts would like to be Data Scientists, they are better to **have research or algorithms experience** and strong knowledge for the following fields, such as Artificial Intelligence, Machine Learning, Data Science, Statistic, Mathematics.\n",
        "\n",
        "If people would like to change career from Data Engineer and Data Scientist to Data Analyst, they not only need to obtain strong hands-on experience on SQL and Python, but also need to improve **Data Visualization skills**, i.e.  Power BI, Tableau, Excel, and reporting / story telling skills. \n",
        "\n",
        "**Figure 3.22**. Schematic Diagram of the Career Path between Data Analyst, Data Engineer and Data Scientist\n",
        "\n",
        "<img src=\"29.png\">"
      ],
      "metadata": {
        "id": "O1Y3jBc0Bm6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Conclusion<a class=\"anchor\" id=\"sec_4\"></a>\n",
        "\n",
        "From the result of analysis, the required fundamental skills among Data Analyst, Data Engineer and Data Scientist are SQL, Python and communication. Moreover, it shows that each of the three job positions has its preferable skills in which Data Analyst needs to have reporting skill; Data Engineer needs to have programming skill; and Data Scientist needs to have mathematical skill."
      ],
      "metadata": {
        "id": "0TXCq4e4Bm6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. References <a class=\"anchor\" id=\"sec_8\"></a>\n",
        "\n",
        "* Saxena, G., & Agarwal, B. B. (2014). Data Warehouse Designing: Dimensional Modelling and ER Modelling. International Journal of Engineering Inventions, 3(9), 28-34.\n"
      ],
      "metadata": {
        "id": "D352UiZtBm6a"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}